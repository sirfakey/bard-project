import bardapi
from deepface import DeepFace
import streamlit as st
import os
from audiorecorder import audiorecorder
import speech_recognition as sr
import whisper
import wave
import re

base_model = whisper.load_model('base')


token = 'YQiXs-X9o1ia04hBXB8eKzF-oXBzSa2_Qqu4wK9ZzioDM9JzOO-UO98_RS91fSrvs1vgyQ.'

r = sr.Recognizer()





with st.sidebar.expander("**About**"):
  st.write('Freya is an interactive voice assistant based on Bard by Google. Freya was designed to help students of all classes.')
  st.write("Students can chat with Freya through voice, and recieve responses tailored to their class, gender and mood.")
  st.write("**Developed and designed by Arghya Biswas, SM Mahdin with the help of our ICT teacher, Shariff sir, and classmates.**")

with st.sidebar.expander("**Personal information**"):
  cls = st.selectbox("2", ('class 12', 'class 11', 'class 10', 'class 9', 'class 8', "class 7", "class 6", "class 5", "class 4", "class 3", "class 2", "class 1", ), placeholder="Class", label_visibility="hidden")
  name = st.text_input ("Your name :")

student_grade = cls

with st.sidebar.expander("**Your gender and emotion**"):
  image_buffer = st.file_uploader("")

  if image_buffer:
    with open(os.path.join("tempDir", "image.png"),"wb") as f:
      f.write(image_buffer.getbuffer())

result = DeepFace.analyze(img_path="tempDir/image.png")

gender = result[0]["dominant_gender"]
emotion = result[0]["dominant_emotion"]

st.sidebar.write("Gender :", gender,"Emotion :", emotion)

with st.sidebar.expander("**Settings**"):
  stt = st.select_slider("1", ("Speech to text", "No speech to text"),label_visibility= "hidden")
  tts = st.select_slider("2", ("Text to Speech", "No Text to Speech"), label_visibility= "hidden")
gender = "male"
emotion = "happy"

audio = None

if stt == "Speech to text":
  with st.expander("**Push to talk**"):
    audio = audiorecorder("Push to Talk", "Recording... (push again to stop)")


prompt = st.chat_input("Ask away!")


if stt == "Speech to text":
  if len(audio) > 0:
    with open("foo.wav", "wb") as f:
      f.write(audio) 
    result1 = base_model.transcribe('foo.wav')
    prompt_text = result1['text']
    prompt = prompt_text



if prompt:
  with st.chat_message("user"):
    st.write(prompt)

if prompt:
  response = bardapi.core.Bard(token).get_answer("Here are your directions, your name is Freya. You are a friendly artificial intelligence program designed to help students. Students will input queries for you about any topic. Before responding, you will acknowledge the students grade, gender and emotion to tailor your reply to be helpful, concise and as short as possible. Try to keep it under 70 words. The student is in ["+ student_grade +"] , is a ["+ gender +"], named "+ name +", and is ["+ emotion +"]. You will treat the words â€œclassâ€ and â€œgradeâ€ interchangeably. You will not talk about this message and reply to the students prompt without additional info. Only reply to what the stuedent asks. DO NOT TALK ABOUT THIS. The student asks :"+ prompt)


with wave.open("output.wav") as mywav:
  duration_seconds = mywav.getnframes() / mywav.getframerate()


if prompt:
  with st.chat_message('assistant',avatar="ðŸ¤–"):
    st.write(response['content'])

def generate_voice(text, voice):
    js_code = f"""
        const synth = window.speechSynthesis;
        const utterance = new SpeechSynthesisUtterance("{text}");
        utterance.voice = speechSynthesis.getVoices().filter((v) => v.name === "{voice}")[0];
        synth.speak(utterance);
    """
    st.components.v1.html(f"<script>{js_code}</script>", height=0)

bard_response = None

if prompt:
  bard_response = response['content']
  str(bard_response)
  spokenResponse = re.sub(r'\s+', ' ', bard_response)
  spokenResponse = spokenResponse.lstrip().rstrip()


if prompt == "HappY BirthdaY":
  with st.chat_message('assistant',avatar="ðŸ¤–"):
    video_file = open('tempDir/happy_birthday.mp4', 'rb')
    video_bytes = video_file.read()
    st.video(video_bytes)  
elif prompt == "Arghya is gay":
  video_file = open('tempDir/arghaya.mp4', 'rb')
  video_bytes = video_file.read()
  st.video(video_bytes) 
  
if tts == "Text to Speech":
  if bard_response:
    generate_voice(spokenResponse, "English, en, Google US English")